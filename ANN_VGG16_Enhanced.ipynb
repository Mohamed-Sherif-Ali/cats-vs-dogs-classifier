{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350fd583",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "VGG16 Baseline - Dog vs Cat Classifier\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "Binary image classification using transfer learning with VGG16.\n",
    "\n",
    "Features:\n",
    "- Transfer learning from ImageNet weights\n",
    "- Data augmentation (flip + brightness)\n",
    "- Early stopping & model checkpointing\n",
    "- Comprehensive evaluation metrics\n",
    "- Confusion matrix & prediction visualization\n",
    "\n",
    "Performance: ~93-94% validation accuracy\n",
    "\n",
    "Author: Mohamed Sherif Ali\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a40432",
   "metadata": {},
   "source": [
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "STEP 1: Import Libraries\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28691db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60eeca31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import AUC, Precision, Recall\n",
    "from tensorflow.keras.callbacks import (\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    "    ReduceLROnPlateau,\n",
    "    CSVLogger,\n",
    "    TensorBoard\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc682a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    "    accuracy_score,\n",
    "    roc_curve,\n",
    "    auc as sklearn_auc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af6f0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"âœ… All libraries imported successfully!\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deecfdab",
   "metadata": {},
   "source": [
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "STEP 2: Configuration & Setup\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3b4ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seeds for reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce04d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 50  # Will stop early with callbacks\n",
    "LEARNING_RATE = 1e-4\n",
    "IMAGE_SIZE = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2421581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directories\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('plots', exist_ok=True)\n",
    "os.makedirs('logs', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55303190",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"  VGG16 BASELINE CONFIGURATION\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"Max Epochs: {EPOCHS}\")\n",
    "print(f\"Learning Rate: {LEARNING_RATE}\")\n",
    "print(f\"Image Size: {IMAGE_SIZE}\")\n",
    "print(f\"Random Seed: {SEED}\")\n",
    "print(f\"{'='*60}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fe349f",
   "metadata": {},
   "source": [
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "STEP 3: GPU Configuration\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63295f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure GPU memory growth (prevents OOM errors)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"âœ… {len(gpus)} GPU(s) configured with memory growth\")\n",
    "        print(f\"   GPUs: {[gpu.name for gpu in gpus]}\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"âš ï¸  GPU configuration error: {e}\")\n",
    "else:\n",
    "    print(\"â„¹ï¸  No GPU detected, using CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d8bde7",
   "metadata": {},
   "source": [
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "STEP 4: Load Dataset\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae82851",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nğŸ“¥ Loading Cats vs Dogs dataset...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb569e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load with seed for reproducibility\n",
    "(train_ds, val_ds), ds_info = tfds.load(\n",
    "    'cats_vs_dogs',\n",
    "    split=['train[:80%]', 'train[80%:]'],\n",
    "    shuffle_files=True,\n",
    "    as_supervised=True,\n",
    "    with_info=True,\n",
    "    read_config=tfds.ReadConfig(shuffle_seed=SEED)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd1343a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display dataset info\n",
    "print(\"\\nğŸ“Š Dataset Information:\")\n",
    "print(f\"Total examples: {ds_info.splits['train'].num_examples}\")\n",
    "print(f\"Training examples: {int(ds_info.splits['train'].num_examples * 0.8)}\")\n",
    "print(f\"Validation examples: {int(ds_info.splits['train'].num_examples * 0.2)}\")\n",
    "print(f\"Classes: {ds_info.features['label'].names}\")\n",
    "print(f\"Features: {ds_info.features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e2214c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Verify a sample\n",
    "print(\"\\nğŸ” Verifying data sample...\")\n",
    "for image, label in train_ds.take(1):\n",
    "    print(f\"Image shape: {image.shape}\")\n",
    "    print(f\"Image dtype: {image.dtype}\")\n",
    "    print(f\"Label: {label.numpy()} ({ds_info.features['label'].names[label.numpy()]})\")\n",
    "    assert image.shape[2] == 3, \"Expected RGB images\"\n",
    "    assert label.numpy() in [0, 1], \"Expected binary labels\"\n",
    "print(\"âœ… Data verification passed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3069b918",
   "metadata": {},
   "source": [
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "STEP 5: Data Preprocessing\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d480409",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def preprocess(image, label):\n",
    "    \"\"\"\n",
    "    Resize and normalize images\n",
    "    \n",
    "    Args:\n",
    "        image: Input image tensor\n",
    "        label: Class label (0=cat, 1=dog)\n",
    "    \n",
    "    Returns:\n",
    "        Preprocessed image and label\n",
    "    \"\"\"\n",
    "    # Resize to 224x224 (VGG16 input size)\n",
    "    image = tf.image.resize(image, IMAGE_SIZE)\n",
    "    \n",
    "    # Normalize to [0, 1] range\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9fba15",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def augment(image, label):\n",
    "    \"\"\"\n",
    "    Apply data augmentation to training images\n",
    "    \n",
    "    Augmentations:\n",
    "    - Random horizontal flip (50% chance)\n",
    "    - Random brightness adjustment (Â±10%)\n",
    "    \n",
    "    Args:\n",
    "        image: Preprocessed image\n",
    "        label: Class label\n",
    "    \n",
    "    Returns:\n",
    "        Augmented image and label\n",
    "    \"\"\"\n",
    "    # Random horizontal flip\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    \n",
    "    # Random brightness adjustment\n",
    "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
    "    \n",
    "    # Clip values to [0, 1] range\n",
    "    image = tf.clip_by_value(image, 0.0, 1.0)\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053777a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nâœ… Preprocessing functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe63ff82",
   "metadata": {},
   "source": [
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "STEP 6: Create Data Pipeline\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f72d898",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nğŸ”„ Building optimized data pipeline...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a058410",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6b2c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training pipeline with caching and prefetching\n",
    "train_batches = (train_ds\n",
    "    .cache()  # Cache preprocessed data in memory\n",
    "    .map(preprocess, num_parallel_calls=AUTOTUNE)\n",
    "    .map(augment, num_parallel_calls=AUTOTUNE)\n",
    "    .shuffle(buffer_size=10000, seed=SEED)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTOTUNE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21789e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation pipeline (no augmentation)\n",
    "val_batches = (val_ds\n",
    "    .cache()\n",
    "    .map(preprocess, num_parallel_calls=AUTOTUNE)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(AUTOTUNE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a8cc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count batches\n",
    "train_batch_count = tf.data.experimental.cardinality(train_batches).numpy()\n",
    "val_batch_count = tf.data.experimental.cardinality(val_batches).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5d4d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"âœ… Training batches: {train_batch_count}\")\n",
    "print(f\"âœ… Validation batches: {val_batch_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a6b2af",
   "metadata": {},
   "source": [
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "STEP 7: Build VGG16 Model\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da995ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nğŸ—ï¸  Building VGG16 model...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddc8067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-trained VGG16 (without top classification layer)\n",
    "base_model = VGG16(\n",
    "    weights='imagenet',\n",
    "    include_top=False,\n",
    "    input_shape=(224, 224, 3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9805894d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze base model weights (transfer learning)\n",
    "base_model.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d766740",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"âœ… VGG16 base loaded with {len(base_model.layers)} layers (frozen)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6e41d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build classifier on top\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(name='global_avg_pool'),\n",
    "    Dense(256, activation='relu', name='dense_256'),\n",
    "    Dropout(0.5, name='dropout_0.5'),\n",
    "    Dense(1, activation='sigmoid', name='output')\n",
    "], name='VGG16_Classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726291fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display model summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL ARCHITECTURE\")\n",
    "print(\"=\"*60)\n",
    "model.summary()\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ded15d6",
   "metadata": {},
   "source": [
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "STEP 8: Compile Model\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc95787",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nâš™ï¸  Compiling model...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ed3c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom optimizer with specific learning rate\n",
    "optimizer = Adam(learning_rate=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcbbbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile with multiple metrics\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='binary_crossentropy',\n",
    "    metrics=[\n",
    "        'accuracy',\n",
    "        AUC(name='auc'),\n",
    "        Precision(name='precision'),\n",
    "        Recall(name='recall')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ccd533",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"âœ… Model compiled with:\")\n",
    "print(f\"   Optimizer: Adam (lr={LEARNING_RATE})\")\n",
    "print(f\"   Loss: Binary Crossentropy\")\n",
    "print(f\"   Metrics: Accuracy, AUC, Precision, Recall\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c6cb10",
   "metadata": {},
   "source": [
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "STEP 9: Setup Callbacks\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a10133",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nğŸ“ Setting up training callbacks...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7738aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timestamp for file versioning\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dbe7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks\n",
    "callbacks = [\n",
    "    # Early stopping - stop when validation loss stops improving\n",
    "    EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=5,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # Model checkpoint - save best model\n",
    "    ModelCheckpoint(\n",
    "        filepath=f'models/vgg16_best_{timestamp}_{{epoch:02d}}_{{val_accuracy:.4f}}.h5',\n",
    "        monitor='val_accuracy',\n",
    "        save_best_only=True,\n",
    "        mode='max',\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # Reduce learning rate on plateau\n",
    "    ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=2,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    ),\n",
    "    \n",
    "    # CSV logger - save training history\n",
    "    CSVLogger(\n",
    "        filename=f'logs/training_log_vgg16_{timestamp}.csv',\n",
    "        append=False\n",
    "    ),\n",
    "    \n",
    "    # TensorBoard - visualize training\n",
    "    TensorBoard(\n",
    "        log_dir=f'logs/tensorboard_vgg16_{timestamp}',\n",
    "        histogram_freq=1\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e2c682",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"âœ… Callbacks configured:\")\n",
    "print(\"   â€¢ Early Stopping (patience=5)\")\n",
    "print(\"   â€¢ Model Checkpoint (save best)\")\n",
    "print(\"   â€¢ Learning Rate Reduction (factor=0.5)\")\n",
    "print(\"   â€¢ CSV Logger\")\n",
    "print(\"   â€¢ TensorBoard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7061d9d2",
   "metadata": {},
   "source": [
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "STEP 10: Train Model\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01bac62",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"  STARTING TRAINING\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Max Epochs: {EPOCHS}\")\n",
    "print(f\"Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"Training Batches: {train_batch_count}\")\n",
    "print(f\"Validation Batches: {val_batch_count}\")\n",
    "print(\"=\"*60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3384c2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_batches,\n",
    "    validation_data=val_batches,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c362aeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"  TRAINING COMPLETED\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Epochs trained: {len(history.history['accuracy'])}\")\n",
    "print(f\"Best validation accuracy: {max(history.history['val_accuracy']):.4f}\")\n",
    "print(f\"Best validation loss: {min(history.history['val_loss']):.4f}\")\n",
    "print(\"=\"*60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790683b0",
   "metadata": {},
   "source": [
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "STEP 11: Plot Training History\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812b5e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ“Š Generating training plots...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056eb28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract history\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs_range = range(len(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beab04fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure with subplots\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91ef82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy plot\n",
    "axes[0].plot(epochs_range, acc, 'b-', label='Training Accuracy', linewidth=2)\n",
    "axes[0].plot(epochs_range, val_acc, 'r-', label='Validation Accuracy', linewidth=2)\n",
    "axes[0].set_title('Training and Validation Accuracy', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Accuracy', fontsize=12)\n",
    "axes[0].legend(fontsize=10)\n",
    "axes[0].grid(True, alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3458f957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss plot\n",
    "axes[1].plot(epochs_range, loss, 'b-', label='Training Loss', linewidth=2)\n",
    "axes[1].plot(epochs_range, val_loss, 'r-', label='Validation Loss', linewidth=2)\n",
    "axes[1].set_title('Training and Validation Loss', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('Loss', fontsize=12)\n",
    "axes[1].legend(fontsize=10)\n",
    "axes[1].grid(True, alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bc582d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.tight_layout()\n",
    "plt.savefig(f'plots/vgg16_training_curves_{timestamp}.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93220896",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"âœ… Training curves saved to: plots/vgg16_training_curves_{timestamp}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260c68c5",
   "metadata": {},
   "source": [
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "STEP 12: Evaluate Model\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd07340c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"  MODEL EVALUATION\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0c18f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on validation set\n",
    "print(\"\\nğŸ” Evaluating on validation set...\")\n",
    "results = model.evaluate(val_batches, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98211035",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nğŸ“Š Final Metrics:\")\n",
    "for metric_name, value in zip(model.metrics_names, results):\n",
    "    print(f\"   {metric_name.capitalize()}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c60384a",
   "metadata": {},
   "source": [
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "STEP 13: Generate Predictions\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c56c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nğŸ”® Generating predictions on validation set...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9825d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict all validation data (fast batch prediction)\n",
    "y_pred_proba = model.predict(val_batches, verbose=1)\n",
    "y_pred = (y_pred_proba > 0.5).astype(\"int32\").flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bdd773",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get true labels\n",
    "y_true = np.concatenate([labels.numpy() for _, labels in val_batches])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb22b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"âœ… Predictions generated for {len(y_true)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a747c8",
   "metadata": {},
   "source": [
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "STEP 14: Confusion Matrix\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6048fd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nğŸ“Š Creating confusion matrix...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69913ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d2b2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt='d',\n",
    "    cmap='Blues',\n",
    "    xticklabels=['Cat', 'Dog'],\n",
    "    yticklabels=['Cat', 'Dog'],\n",
    "    cbar_kws={'label': 'Count'},\n",
    "    annot_kws={'size': 16, 'weight': 'bold'}\n",
    ")\n",
    "plt.xlabel('Predicted Label', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('True Label', fontsize=12, fontweight='bold')\n",
    "plt.title('VGG16 Confusion Matrix', fontsize=14, fontweight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6c4b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add accuracy to plot\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "plt.text(\n",
    "    0.5, -0.15,\n",
    "    f'Overall Accuracy: {accuracy:.2%}',\n",
    "    ha='center',\n",
    "    transform=plt.gca().transAxes,\n",
    "    fontsize=12,\n",
    "    fontweight='bold'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cd64fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.tight_layout()\n",
    "plt.savefig(f'plots/vgg16_confusion_matrix_{timestamp}.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042118ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"âœ… Confusion matrix saved to: plots/vgg16_confusion_matrix_{timestamp}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edaf3714",
   "metadata": {},
   "source": [
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "STEP 15: Classification Report\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84826850",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"  CLASSIFICATION REPORT\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc00eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate classification report\n",
    "report = classification_report(\n",
    "    y_true,\n",
    "    y_pred,\n",
    "    target_names=['Cat', 'Dog'],\n",
    "    digits=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116c7c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0aa00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate additional metrics\n",
    "tn, fp, fn, tp = cm.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f051b687",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"  DETAILED METRICS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"True Negatives (Catâ†’Cat):   {tn:,}\")\n",
    "print(f\"False Positives (Catâ†’Dog):  {fp:,}\")\n",
    "print(f\"False Negatives (Dogâ†’Cat):  {fn:,}\")\n",
    "print(f\"True Positives (Dogâ†’Dog):   {tp:,}\")\n",
    "print(f\"\\nOverall Accuracy: {accuracy:.4f} ({accuracy:.2%})\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795680d2",
   "metadata": {},
   "source": [
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "STEP 16: Prediction Visualization\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa85889",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nğŸ–¼ï¸  Creating prediction visualization grid...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a2dd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect sample images\n",
    "val_images_list = []\n",
    "val_labels_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5210a6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for images, labels in val_batches.take(5):\n",
    "    val_images_list.append(images.numpy())\n",
    "    val_labels_list.append(labels.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da61ba1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stack all images and labels\n",
    "val_images_array = np.vstack(val_images_list)\n",
    "val_labels_array = np.concatenate(val_labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0d87fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on these samples\n",
    "sample_preds = model.predict(val_images_array[:160], verbose=0)\n",
    "sample_pred_classes = (sample_preds > 0.5).astype(\"int32\").flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50b1fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample unique indices (no duplicates)\n",
    "num_samples = 15\n",
    "total_available = len(val_images_array[:160])\n",
    "indices = random.sample(range(total_available), min(num_samples, total_available))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22878fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization grid\n",
    "fig, axes = plt.subplots(3, 5, figsize=(15, 10))\n",
    "axes = axes.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da90237",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, idx in enumerate(indices):\n",
    "    if i >= 15:\n",
    "        break\n",
    "    \n",
    "    # Get image, true label, and prediction\n",
    "    img = val_images_array[idx]\n",
    "    true_label = val_labels_array[idx]\n",
    "    pred_label = sample_pred_classes[idx]\n",
    "    pred_conf = sample_preds[idx][0]\n",
    "    \n",
    "    # Convert labels to names\n",
    "    true_name = \"Dog\" if true_label == 1 else \"Cat\"\n",
    "    pred_name = \"Dog\" if pred_label == 1 else \"Cat\"\n",
    "    \n",
    "    # Determine color (green if correct, red if wrong)\n",
    "    color = 'green' if true_label == pred_label else 'red'\n",
    "    \n",
    "    # Plot image\n",
    "    axes[i].imshow(img)\n",
    "    axes[i].axis('off')\n",
    "    \n",
    "    # Add title with prediction\n",
    "    title = f\"True: {true_name}\\nPred: {pred_name}\"\n",
    "    if true_label == pred_label:\n",
    "        title += f\"\\n(Conf: {pred_conf:.2%})\"\n",
    "    else:\n",
    "        title += f\"\\n(Conf: {pred_conf:.2%}) âŒ\"\n",
    "    \n",
    "    axes[i].set_title(title, color=color, fontweight='bold', fontsize=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25a3cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.suptitle(\n",
    "    'VGG16: Sample Predictions (Green=Correct, Red=Wrong)',\n",
    "    fontsize=16,\n",
    "    fontweight='bold',\n",
    "    y=1.02\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'plots/vgg16_predictions_{timestamp}.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b0754a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"âœ… Prediction grid saved to: plots/vgg16_predictions_{timestamp}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c14abc",
   "metadata": {},
   "source": [
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "STEP 17: Save Model & Metadata\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7f2f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nğŸ’¾ Saving final model and metadata...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2583f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final model (in addition to best checkpoint)\n",
    "final_model_path = f'models/vgg16_final_{timestamp}.h5'\n",
    "model.save(final_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9617b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create metadata\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427f64e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {\n",
    "    'model_name': 'VGG16_Baseline',\n",
    "    'timestamp': timestamp,\n",
    "    'architecture': {\n",
    "        'base_model': 'VGG16',\n",
    "        'input_shape': [224, 224, 3],\n",
    "        'trainable_params': int(np.sum([tf.size(w).numpy() for w in model.trainable_weights])),\n",
    "        'total_params': int(np.sum([tf.size(w).numpy() for w in model.weights]))\n",
    "    },\n",
    "    'hyperparameters': {\n",
    "        'batch_size': BATCH_SIZE,\n",
    "        'epochs_trained': len(history.history['accuracy']),\n",
    "        'max_epochs': EPOCHS,\n",
    "        'learning_rate': float(LEARNING_RATE),\n",
    "        'optimizer': 'Adam',\n",
    "        'loss': 'binary_crossentropy'\n",
    "    },\n",
    "    'performance': {\n",
    "        'final_train_accuracy': float(acc[-1]),\n",
    "        'final_val_accuracy': float(val_acc[-1]),\n",
    "        'best_val_accuracy': float(max(val_acc)),\n",
    "        'final_train_loss': float(loss[-1]),\n",
    "        'final_val_loss': float(val_loss[-1]),\n",
    "        'best_val_loss': float(min(val_loss)),\n",
    "        'overall_accuracy': float(accuracy),\n",
    "        'precision': float(tp / (tp + fp)),\n",
    "        'recall': float(tp / (tp + fn))\n",
    "    },\n",
    "    'dataset': {\n",
    "        'name': 'cats_vs_dogs',\n",
    "        'train_samples': int(ds_info.splits['train'].num_examples * 0.8),\n",
    "        'val_samples': int(ds_info.splits['train'].num_examples * 0.2),\n",
    "        'classes': ds_info.features['label'].names\n",
    "    },\n",
    "    'files': {\n",
    "        'model': final_model_path,\n",
    "        'training_log': f'logs/training_log_vgg16_{timestamp}.csv',\n",
    "        'confusion_matrix': f'plots/vgg16_confusion_matrix_{timestamp}.png',\n",
    "        'training_curves': f'plots/vgg16_training_curves_{timestamp}.png',\n",
    "        'predictions': f'plots/vgg16_predictions_{timestamp}.png'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda02a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metadata\n",
    "metadata_path = f'models/metadata_vgg16_{timestamp}.json'\n",
    "with open(metadata_path, 'w') as f:\n",
    "    json.dump(metadata, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370b6e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"âœ… Model saved to: {final_model_path}\")\n",
    "print(f\"âœ… Metadata saved to: {metadata_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13195238",
   "metadata": {},
   "source": [
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "STEP 18: Summary\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971c5d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"  TRAINING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Model: VGG16 Baseline\")\n",
    "print(f\"Epochs Trained: {len(history.history['accuracy'])}/{EPOCHS}\")\n",
    "print(f\"Best Validation Accuracy: {max(val_acc):.2%}\")\n",
    "print(f\"Final Test Accuracy: {accuracy:.2%}\")\n",
    "print(f\"\\nFiles Generated:\")\n",
    "print(f\"  â€¢ Model: {final_model_path}\")\n",
    "print(f\"  â€¢ Metadata: {metadata_path}\")\n",
    "print(f\"  â€¢ Training curves: plots/vgg16_training_curves_{timestamp}.png\")\n",
    "print(f\"  â€¢ Confusion matrix: plots/vgg16_confusion_matrix_{timestamp}.png\")\n",
    "print(f\"  â€¢ Predictions: plots/vgg16_predictions_{timestamp}.png\")\n",
    "print(f\"  â€¢ Training log: logs/training_log_vgg16_{timestamp}.csv\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nâœ… VGG16 BASELINE TRAINING COMPLETE! ğŸ•ğŸˆ\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
